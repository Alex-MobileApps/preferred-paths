{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ml import BrainDataset, PolicyEstimator, reinforce"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Input Parameters\n",
    "num_fns = 6\n",
    "save_path = None\n",
    "load_path = None\n",
    "res = 68\n",
    "subj = [0]\n",
    "epochs = 5000\n",
    "batch = 1\n",
    "hidden_units = 20\n",
    "lr = 0.005\n",
    "save_path = None\n",
    "load_path = None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Read brain data (change file locations as necessary)\n",
    "sc = loadmat(f'data/subjfiles_SC{res}.mat')\n",
    "fc = loadmat(f'data/subjfiles_FC{res}.mat')\n",
    "sc = np.array([sc[f's{str(z+1).zfill(3)}'] for z in subj])\n",
    "fc = np.array([fc[f's{str(z+1).zfill(3)}'] for z in subj])\n",
    "euc_dist = loadmat('data/euc_dist.mat')[f'eu{res}']\n",
    "hubs = np.loadtxt(f'data/hubs_{res}.txt', dtype=np.int, delimiter=',')\n",
    "regions = np.loadtxt(f'data/regions_{res}.txt', dtype=np.int, delimiter=',')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Init network parameters\n",
    "pe = PolicyEstimator(res, num_fns)\n",
    "opt = torch.optim.Adam(pe.network.parameters(), lr=lr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Init new/load previous training data\n",
    "if load_path:\n",
    "    # Load from checkpoint\n",
    "    checkpoint = torch.load(load_path)\n",
    "    plt_data = {k: checkpoint[k] for k in ('rewards','success','mu','sig','train_idx','test_idx')}\n",
    "    pe.network.load_state_dict(checkpoint['model_state_dict'])\n",
    "    opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "else:\n",
    "    # New\n",
    "    plt_data = {\n",
    "        'rewards': [],\n",
    "        'success': [],\n",
    "        'mu': [[] for _ in range(num_fns)],\n",
    "        'sig': [[] for _ in range(num_fns)]}\n",
    "    plt_data['train_idx'], plt_data['test_idx'] = train_test_split(subj, train_size=0.7) if len(subj) > 1 else (subj, [])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Train / test split\n",
    "train_idx, test_idx = plt_data['train_idx'], plt_data['test_idx']\n",
    "train_data = BrainDataset(sc[train_idx], fc[train_idx], euc_dist, hubs, regions)\n",
    "test_data =  BrainDataset(sc[test_idx],  fc[test_idx],  euc_dist, hubs, regions)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Reinforce and save after each epoch\n",
    "reinforce(pe, opt, train_data, epochs=epochs, batch=batch, lr=lr, plt_data=plt_data, inc_plt=True, plt_freq=5, plt_off=0, plt_avg=50)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Most recent reward\n",
    "plt_data['rewards'][-1]"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "a876d5d129613f84737ac732b9dceeab4d5b6e46c5cd6a0b580a7fe744c52632"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}